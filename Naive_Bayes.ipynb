{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Naive Bayes, Clearly Explained!!!](https://www.youtube.com/watch?v=O2L2Uv9pdDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jlam.nbdev as nbdev\n",
    "nbdev.parse_nb(\"Naive_Bayes.ipynb\",\"naive_bayes.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<<export>>\n",
    "from typing import Set, NamedTuple\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text: str) -> Set[str]:\n",
    "    text = text.lower() # Convert to lowercase\n",
    "    all_words = re.findall(\"[a-z0-9]+\",text) # extract the words\n",
    "    return set(all_words) # remove duplicates\n",
    "\n",
    "assert tokenize(\"Data Science is Science\") == {\"data\",'science','is'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<<export>>\n",
    "class Message(NamedTuple):\n",
    "    text: str\n",
    "    is_spam: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The constructor will take just one parameter, the pseudocount to use when computing probabilities. It also initializes an empty set of tokens, counters to track how often each token is seen in spam messages and ham messages, and counts of how many spam and ham messages it was trained on:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#<<export>>\n",
    "from typing import List, Tuple, Dict, Iterable\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, k: float = 0.5) -> None:\n",
    "        self.k = k # smoothing factor\n",
    "        self.tokens: Set[str] = set()\n",
    "        self.token_spam_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.token_ham_counts: Dict[str, int] = defaultdict(int)\n",
    "        self.spam_messages = self.ham_messages = 0\n",
    "        \n",
    "    def train(self, messages: Iterable[Message]) -> None:\n",
    "        for message in messages:\n",
    "            # Increment message counts\n",
    "            if message.is_spam:\n",
    "                self.spam_messages += 1\n",
    "            else:\n",
    "                self.ham_messages += 1\n",
    "                \n",
    "            # Increment word counts\n",
    "            for token in tokenize(message.text):\n",
    "                self.tokens.add(token)\n",
    "                if message.is_spam:\n",
    "                    self.token_spam_counts[token] += 1\n",
    "                else:\n",
    "                    self.token_ham_counts[token] += 1\n",
    "                    \n",
    "    def _probabilities(self, token: str) -> Tuple[float, float]:\n",
    "        \"\"\"returns P(token | spam) and P(token | ham)\"\"\"\n",
    "        spam = self.token_spam_counts[token]\n",
    "        ham = self.token_ham_counts[token]\n",
    "        \n",
    "        p_token_spam = (spam + self.k) / (self.spam_messages + 2 * self.k)\n",
    "        p_token_ham = (ham + self.k) / (self.ham_messages + 2 * self.k)\n",
    "        \n",
    "        return p_token_spam, p_token_ham\n",
    "        \n",
    "        \n",
    "    def predict(self, text: str) -> float:\n",
    "        text_tokens = tokenize(text)\n",
    "        log_prob_if_spam = log_prob_if_ham = 0.0\n",
    "        \n",
    "        #iterate through each word in our vocabulary\n",
    "        for token in self.tokens:\n",
    "            prob_if_spam, prob_if_ham = self._probabilities(token)\n",
    "            \n",
    "            # If *token* appears in the message,\n",
    "            # add the log probability of seeing it\n",
    "            if token in text_tokens:\n",
    "                log_prob_if_spam += math.log(prob_if_spam)\n",
    "                log_prob_if_ham += math.log(prob_if_ham)\n",
    "                \n",
    "            # otherwise add the log probability of not seeing it\n",
    "            # which is log(1 - probability of seeing it)\n",
    "            else:\n",
    "                log_prob_if_spam += math.log(1.0 - prob_if_spam)\n",
    "                log_prob_if_ham += math.log(1.0 - prob_if_ham)\n",
    "                \n",
    "        prob_if_spam = math.exp(log_prob_if_spam)\n",
    "        prob_if_ham = math.exp(log_prob_if_ham)\n",
    "        return prob_if_spam / (prob_if_spam + prob_if_ham)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [Message(\"spam rules\", is_spam=True),\n",
    "           Message(\"ham rules\", is_spam=False),\n",
    "           Message(\"hello ham\", is_spam=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NaiveBayesClassifier(k=0.5)\n",
    "model.train(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.tokens == {\"spam\",\"ham\",\"rules\",\"hello\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.spam_messages == 1\n",
    "assert model.ham_messages == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.token_spam_counts == {\"spam\":1, \"rules\":1}\n",
    "assert model.token_ham_counts == {\"ham\":2, \"rules\":1, \"hello\":1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello spam\"\n",
    "\n",
    "probs_if_spam = [\n",
    "    (1 + 0.5) / (1 + 2 * 0.5), # \"spam\" _present\n",
    "    1 - (0 + 0.5) / (1 + 2 * 0.5), # \"ham\" not present\n",
    "    1 - (1 + 0.5) / (1 + 2 * 0.5), # \"rules\" not present\n",
    "    (0 + 0.5) / (1 + 2 * 0.5) # \"hello\" present\n",
    "]\n",
    "\n",
    "probs_if_ham = [\n",
    "    (0 + 0.5) / (2 + 2 * 0.5), # \"spam\" _present\n",
    "    1 - (2 + 0.5) / (2 + 2 * 0.5), # \"ham\" not present\n",
    "    1 - (1 + 0.5) / (2 + 2 * 0.5), # \"rules\" not present\n",
    "    (1 + 0.5) / (2 + 2 * 0.5), # \"hello\" present\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_if_spam = math.exp(sum(math.log(p) for p in probs_if_spam))\n",
    "p_if_ham = math.exp(sum(math.log(p) for p in probs_if_ham))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350515463917525"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8350515463917525"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert model.predict(text) == p_if_spam / (p_if_spam + p_if_ham)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.1699250014423126"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "math.log(9,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO # So we can treat bytes as a file\n",
    "import requests # To download the files, which\n",
    "import tarfile  # are in .tar.bz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://spamassassin.apache.org/old/publiccorpus\"\n",
    "FILES = [\"20021010_easy_ham.tar.bz2\",\n",
    "        \"20021010_hard_ham.tar.bz2\",\n",
    "         \"20021010_spam.tar.bz2\"\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'spam_data'\n",
    "for filename in FILES:\n",
    "    content = requests.get(f\"{BASE_URL}/{filename}\").content\n",
    "    fin = BytesIO(content)\n",
    "    with tarfile.open(fileobj=fin, mode='r:bz2') as tf:\n",
    "        tf.extractall(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34measy_ham\u001b[m\u001b[m \u001b[34mhard_ham\u001b[m\u001b[m \u001b[34mspam\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls spam_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at subject line of each file\n",
    "import glob, re\n",
    "\n",
    "path = 'spam_data/*/*'\n",
    "\n",
    "data: List[Message] = []\n",
    "    \n",
    "# glob.glob returns every filename that matches the wildcarded path\n",
    "for filename in glob.glob(path):\n",
    "    is_spam = \"ham\" not in filename\n",
    "    \n",
    "    # Thereare some garbage characters in the emails; skips them instead of raising an exception\n",
    "    with open(filename, errors='ignore') as email_file:\n",
    "        for line in email_file:\n",
    "            if line.startswith(\"Subject:\"):\n",
    "                subject = line.lstrip(\"Subject: \")\n",
    "                data.append(Message(subject, is_spam))\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting data into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from scratch.machine_learning import split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "train_messages, test_messages = split_data(data, 0.75)\n",
    "\n",
    "model = NaiveBayesClassifier()\n",
    "model.train(train_messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "predictions = [(message, model.predict(message.text))\n",
    "                  for message in test_messages\n",
    "              ]\n",
    "\n",
    "# Assume that spam_probability > 0.5 corresponds to spam prediction\n",
    "# and count the combinations of (actual is_spam, predicted is_spam)\n",
    "\n",
    "confusion_matrix = Counter((message.is_spam, spam_probability > 0.5)\n",
    "                            for message, spam_probability in predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negative: (False, False) \n",
      " True Positive: (True, True) \n",
      " False Negative: (True, False) \n",
      " False Positive: (False, True)\n",
      "Counter({(False, False): 664, (True, True): 85, (True, False): 54, (False, True): 22})\n"
     ]
    }
   ],
   "source": [
    "print(\"True Negative: (False, False) \\n True Positive: (True, True) \\n False Negative: (True, False) \\n False Positive: (False, True)\")\n",
    "print(confusion_matrix)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794392523364486"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision = 85 / (85 + 22)\n",
    "precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### inspect inner words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def p_spam_given_token(token: str, model: NaiveBayesClassifier) -> float:\n",
    "    # shouldn't call private method\n",
    "    prob_if_spam, prob_if_ham = model._probabilities(token)\n",
    "    return prob_if_spam / (prob_if_spam + prob_if_ham)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam_dic = {}\n",
    "for t in model.tokens:\n",
    "    p_spam_dic[t]=p_spam_given_token(t,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mirror': 0.6607310215557638,\n",
       " 'bad': 0.1363724289122445,\n",
       " 'affiliate': 0.8538554703270085,\n",
       " 'yahoo': 0.2176597715344242,\n",
       " 'copy': 0.7780502759043532}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "dict(itertools.islice(p_spam_dic.items(),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = sorted(model.tokens, key=lambda t: p_spam_given_token(t,model), reverse=True)\n",
    "# words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adv: 0.9945090782228829\n",
      "rates: 0.9945090782228829\n",
      "systemworks: 0.9919154923286508\n",
      "money: 0.9919154923286508\n",
      "zzzz: 0.9910720891804572\n",
      "sale: 0.9900322163174271\n",
      "attn: 0.9900322163174271\n",
      "account: 0.9900322163174271\n",
      "per: 0.9887181724686009\n",
      "clearance: 0.9887181724686009\n",
      "95: 0.9887181724686009\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "max=10\n",
    "for t in words:\n",
    "    print(f'{t}: {p_spam_dic[t]}')\n",
    "    cnt += 1\n",
    "    if cnt > max:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spammiest_words ['selling', 'bliss', 'apt', 'ouch', 'sadev', 'zzzzteana', 'razor', 'users', '2', 'spambayes']\n",
      "hammiest_words ['adv', 'rates', 'systemworks', 'money', 'zzzz', 'sale', 'attn', 'account', 'per', 'clearance']\n"
     ]
    }
   ],
   "source": [
    "print(\"spammiest_words\", words[-10:])\n",
    "print(\"hammiest_words\", words[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
